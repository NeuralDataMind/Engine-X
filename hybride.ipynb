{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuralDataMind/Engine-X/blob/main/hybride.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa-kegZTilo3",
        "outputId": "58fd0e75-cd3f-413d-9a32-8d21d3b13b99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse, torch-cluster\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp312-cp312-linux_x86_64.whl size=640889 sha256=e0e410595721e18ec173911d535bab091b30070e532722a6882e37df091ad754\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/20/50/44800723f57cd798630e77b3ec83bc80bd26a1e3dc3a672ef5\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp312-cp312-linux_x86_64.whl size=1158903 sha256=2683d6068a0de5aabc941420db601ffa469a98a8e9ecd9f30560fb8fbfeff458\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/fa/21/bd1d78ce1629aec4ecc924a63b82f6949dda484b6321eac6f2\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.3-cp312-cp312-linux_x86_64.whl size=741928 sha256=1980717b4e67949044bee340121ca91950c86809a50b5dceb5e019096541a428\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/8f/d0/13408a84825c9a587151a74727b4a6d47ec67e0d625b385ad7\n",
            "Successfully built torch-scatter torch-sparse torch-cluster\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
            "Successfully installed torch-cluster-1.6.3 torch-geometric-2.6.1 torch-scatter-2.1.2 torch-sparse-0.6.18\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torch-geometric torch-scatter torch-sparse torch-cluster \\\n",
        "    sentence-transformers scikit-learn pandas numpy tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy1YDfMBhv3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795,
          "referenced_widgets": [
            "06a8f6c6691443d8b585fc265fadb174",
            "987f825816cc4dc28938a4de49889a8c",
            "aa523e74a2ee4fc189b7d0279b156dc2",
            "23e2e81d8de6490ab6b71918d2a7c0d0",
            "266c11a578c14dd388fd651b3a8e8138",
            "b197dd5456194748953319de2e1a6ab2",
            "a4caa3e0cd3d497e90f5bb1882b00165",
            "ffd26d1d3d4443cb9e893052e10e5c1c",
            "d71b94e2e052414e8254435d0d0e8d9d",
            "0fcf1a2ee47a4556b6645db4aed58ac7",
            "284a912d7c8e435abba37b4bf8bd993e",
            "ac4701d881a2496ab6cf550b6f8fe411",
            "68574b0dae7741ac889e0be40136171c",
            "ab8e4c075bdd4f41ad6c9cb247647af5",
            "9d8120369b3849c1ad6f3445ce88e35f",
            "1cb0baaf14004ac3820c700d4e76cf0c",
            "f518c73749f441a8a0c888da7c16b5ef",
            "efb3a9f65ec74b2098913f5463663e15",
            "366c8250dc8442d1a6a05552683f25f0",
            "a0768d6a2d564f0eb804b4bcfd5bd2e9",
            "b43b0187755f41329194be72d2ed1914",
            "053130f4bb70432781064ea3c2821f57"
          ]
        },
        "outputId": "9c494ab2-fb59-43dc-8753-0e6d854b9ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "product: (1000, 15)\n",
            "social: (1000, 10)\n",
            "Computing product embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06a8f6c6691443d8b585fc265fadb174"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing social embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac4701d881a2496ab6cf550b6f8fe411"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building product-product edges...\n",
            "pp edges: 10493\n",
            "Building product-social tag-match edges...\n",
            "ps edges from tags: 188\n",
            "Building product-social similarity edges...\n",
            "ps edges from sim: 0\n",
            "Total edges: 21362\n",
            "product_x.shape = torch.Size([1000, 392]), social_x.shape = torch.Size([1000, 385])\n",
            "Padded to match dims -> product_x.shape = torch.Size([1000, 392]), social_x.shape = torch.Size([1000, 392])\n",
            "Merged node feature shape: torch.Size([2000, 392])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Epoch 001 | Loss 35.8134 | Val AUC 0.1511 | Val AP 0.3327\n",
            "Epoch 010 | Loss 24.5363 | Val AUC 0.6353 | Val AP 0.5192\n",
            "Epoch 020 | Loss 14.9444 | Val AUC 0.8704 | Val AP 0.7826\n",
            "Epoch 030 | Loss 6.1798 | Val AUC 0.8618 | Val AP 0.7621\n",
            "Epoch 040 | Loss 4.1663 | Val AUC 0.8693 | Val AP 0.7728\n",
            "Epoch 050 | Loss 3.4061 | Val AUC 0.8724 | Val AP 0.7763\n",
            "Epoch 060 | Loss 3.2001 | Val AUC 0.8713 | Val AP 0.7755\n",
            "Epoch 070 | Loss 2.7730 | Val AUC 0.8831 | Val AP 0.8005\n",
            "Epoch 080 | Loss 2.4817 | Val AUC 0.8878 | Val AP 0.8098\n",
            "Recommended product indices: [941 737 359 824   2 571 674 884  32 886]\n",
            "Scores: [0.9421574  0.88597167 0.8806924  0.87051296 0.8697399  0.8668969\n",
            " 0.8665118  0.86566365 0.86520004 0.8647807 ]\n",
            "Product: c71f191c-2b89-4717-ac6b-63a2308e7ef6 | Bates Beverages | score 0.9422\n",
            "Product: b57615a0-2e25-44dd-8803-56f8c70d7aa7 | Campos Beverages | score 0.8860\n",
            "Product: ec0616f5-5b21-4e67-9987-96965755be70 | Day-Pace Beverages | score 0.8807\n",
            "Product: 07aa8bf0-7280-43b5-905a-fd495098c6b2 | Brady-Richardson Fresh Produce | score 0.8705\n",
            "Product: 7ae8ad84-bf77-4d9b-b73a-16680974495d | Dyer-Price Beverages | score 0.8697\n",
            "Product: fd6aed8a-1e76-42d9-8a1b-80cb90422ca1 | Anderson, Household Essentials | score 0.8669\n",
            "Product: cef7c2d5-a279-4389-bf74-56e9ff87b7b8 | Bryant, Snacks | score 0.8665\n",
            "Product: 417167d0-4780-423d-937b-58e3ca5e1583 | Bell-Shields Beverages | score 0.8657\n",
            "Product: 0205af3f-71f1-489c-902f-0d2f5bca888e | Cross-Rodgers Beverages | score 0.8652\n",
            "Product: 032c7103-edd0-490b-8a9e-89405a9ead22 | Bullock, Household Essentials | score 0.8648\n",
            "Saved embeddings to disk.\n"
          ]
        }
      ],
      "source": [
        "# Engine X - Hybrid Content + Product Recommendation using GNN\n",
        "# Single-file pipeline (run locally).\n",
        "# Assumes you have product_df and social_df saved as CSVs: 'product.csv', 'master_social_sample.csv'\n",
        "# Key ideas implemented:\n",
        "# 1. Preprocess product and social text, numeric features\n",
        "# 2. Create content embeddings (SentenceTransformer)\n",
        "# 3. Build a heterogeneous graph: product nodes + social nodes\n",
        "# 4. Add edges: product-product (content similarity), product-social (tag match & similarity)\n",
        "# 5. Train an unsupervised GraphSAGE encoder using link reconstruction (positive + negative sampling)\n",
        "# 6. Produce final node embeddings and compute hybrid recommendations via weighted similarity\n",
        "\n",
        "# NOTES:\n",
        "# - Install required libs: torch, torch_geometric, sentence-transformers, scikit-learn, pandas, numpy\n",
        "# - For large graphs, use NeighborSampler / mini-batching (PyG). For 1k products + 1k social it's small.\n",
        "# - This script uses CPU/GPU depending on available device.\n",
        "\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# PyG imports\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.utils import negative_sampling, train_test_split_edges\n",
        "\n",
        "# Text / embedding\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Load data (adjust paths)\n",
        "# ---------------------------\n",
        "product_path = '/content/master_product.csv'  # your 1000-row product file\n",
        "social_path = '/content/mini_ms.csv'  # your 1000-row social sample (or subset)\n",
        "\n",
        "product_df = pd.read_csv(product_path)\n",
        "social_df = pd.read_csv(social_path)\n",
        "\n",
        "print('product:', product_df.shape)\n",
        "print('social:', social_df.shape)\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Basic preprocessing\n",
        "# ---------------------------\n",
        "# Fill/normalize fields\n",
        "product_df['tags'] = product_df['tags'].fillna('').astype(str)\n",
        "product_df['product_name'] = product_df['product_name'].fillna('').astype(str)\n",
        "product_df['brand'] = product_df['brand'].fillna('unknown').astype(str)\n",
        "\n",
        "social_df['text'] = social_df['text'].fillna('').astype(str)\n",
        "social_df['matched_tags'] = social_df['matched_tags'].fillna('').astype(str)\n",
        "\n",
        "# Convert created_time if necessary\n",
        "# If created_time is numeric epoch, convert to datetime\n",
        "try:\n",
        "    if np.issubdtype(social_df['created_time'].dtype, np.number):\n",
        "        social_df['created_time'] = pd.to_datetime(social_df['created_time'], unit='s')\n",
        "    else:\n",
        "        social_df['created_time'] = pd.to_datetime(social_df['created_time'], errors='coerce')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Generate content embeddings\n",
        "# ---------------------------\n",
        "# Use a compact sentence-transformer model (user can replace with any model).\n",
        "embed_model_name = 'all-MiniLM-L6-v2'  # small & fast\n",
        "embedder = SentenceTransformer(embed_model_name)\n",
        "\n",
        "# Compose product text (name + tags + brand + category)\n",
        "product_texts = (\n",
        "    product_df['product_name'].str.strip() + ' | ' +\n",
        "    product_df['tags'].str.strip() + ' | ' +\n",
        "    product_df['brand'].str.strip() + ' | ' +\n",
        "    product_df['category'].str.strip()\n",
        ").tolist()\n",
        "\n",
        "social_texts = social_df['text'].tolist()\n",
        "\n",
        "# Compute embeddings (convert to float32 tensors)\n",
        "print('Computing product embeddings...')\n",
        "product_emb = embedder.encode(product_texts, show_progress_bar=True, convert_to_numpy=True)\n",
        "print('Computing social embeddings...')\n",
        "social_emb = embedder.encode(social_texts, show_progress_bar=True, convert_to_numpy=True)\n",
        "\n",
        "# Optionally reduce dimensionality using PCA/UMAP if needed for speed (not done here)\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Build features for nodes\n",
        "# ---------------------------\n",
        "# Product numeric features\n",
        "num_cols = ['mrp_inr', 'price_inr', 'discount_inr', 'discount_pct', 'rating', 'reviews_count', 'score']\n",
        "product_num = product_df[num_cols].fillna(0).values.astype(np.float32)\n",
        "scaler = StandardScaler()\n",
        "product_num_scaled = scaler.fit_transform(product_num)\n",
        "\n",
        "# Encode category/brand with LabelEncoder and one-hot or embedding index\n",
        "le_brand = LabelEncoder()\n",
        "product_brand_idx = le_brand.fit_transform(product_df['brand'].astype(str))\n",
        "product_brand_idx = product_brand_idx.reshape(-1, 1).astype(np.float32)\n",
        "\n",
        "# Final product feature vector: [content_emb || numeric || brand_idx]\n",
        "product_feat = np.concatenate([product_emb.astype(np.float32), product_num_scaled, product_brand_idx], axis=1)\n",
        "\n",
        "# Social node features: use social_emb and some simple numeric\n",
        "social_time_delta = (pd.Timestamp.now() - social_df['created_time']).dt.total_seconds().fillna(0).values.reshape(-1,1).astype(np.float32)\n",
        "# pad/concat\n",
        "social_feat = np.concatenate([social_emb.astype(np.float32), social_time_delta], axis=1)\n",
        "\n",
        "# Convert to torch tensors\n",
        "product_x = torch.from_numpy(product_feat)\n",
        "social_x = torch.from_numpy(social_feat)\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Create edges\n",
        "# ---------------------------\n",
        "# We'll create three types of edges (undirected):\n",
        "#  - product-product by content similarity (kNN)\n",
        "#  - product-social by exact tag match\n",
        "#  - product-social by text similarity (thresholded)\n",
        "\n",
        "def build_pp_edges_from_similarity(embeddings, top_k=10, min_sim=0.6):\n",
        "    # embeddings: numpy array\n",
        "    sims = cosine_similarity(embeddings)\n",
        "    edges = set()\n",
        "    n = sims.shape[0]\n",
        "    for i in range(n):\n",
        "        # get top_k indices excluding self\n",
        "        idxs = np.argsort(-sims[i])[: top_k + 1]\n",
        "        for j in idxs:\n",
        "            if i == j:\n",
        "                continue\n",
        "            if sims[i, j] >= min_sim:\n",
        "                a, b = sorted((i, j))\n",
        "                edges.add((a, b))\n",
        "    return list(edges)\n",
        "\n",
        "print('Building product-product edges...')\n",
        "pp_edges = build_pp_edges_from_similarity(product_emb, top_k=20, min_sim=0.65)\n",
        "print(f'pp edges: {len(pp_edges)}')\n",
        "\n",
        "# product-social edges: tag exact matches\n",
        "print('Building product-social tag-match edges...')\n",
        "prod_tag_map = {}\n",
        "for idx, tags in enumerate(product_df['tags'].astype(str)):\n",
        "    for t in [tt.strip().lower() for tt in tags.split(',') if tt.strip()]:\n",
        "        prod_tag_map.setdefault(t, []).append(idx)\n",
        "\n",
        "ps_edges = set()\n",
        "for s_idx, tags in enumerate(social_df['matched_tags'].astype(str)):\n",
        "    for t in [tt.strip().lower() for tt in tags.split(',') if tt.strip()]:\n",
        "        if t in prod_tag_map:\n",
        "            for p_idx in prod_tag_map[t]:\n",
        "                # product node ids will be 0..P-1, social nodes P..P+S-1\n",
        "                ps_edges.add((p_idx, s_idx))\n",
        "\n",
        "print(f'ps edges from tags: {len(ps_edges)}')\n",
        "\n",
        "# product-social edges by embedding similarity (thresholded)\n",
        "print('Building product-social similarity edges...')\n",
        "ps_sim_edges = set()\n",
        "ps_sim_matrix = cosine_similarity(product_emb, social_emb)\n",
        "P, S = ps_sim_matrix.shape\n",
        "threshold = 0.7\n",
        "for i in range(P):\n",
        "    # connect to top matches above threshold\n",
        "    idxs = np.where(ps_sim_matrix[i] >= threshold)[0]\n",
        "    for j in idxs:\n",
        "        ps_sim_edges.add((i, j))\n",
        "\n",
        "print(f'ps edges from sim: {len(ps_sim_edges)}')\n",
        "\n",
        "# Convert to homogeneous edge_index for torch_geometric\n",
        "# Node indexing: 0..P-1 -> product nodes; P..P+S-1 -> social nodes\n",
        "P = product_x.size(0)\n",
        "S = social_x.size(0)\n",
        "\n",
        "edge_list = []\n",
        "# add product-product edges (make bidirectional)\n",
        "for a, b in pp_edges:\n",
        "    edge_list.append((a, b))\n",
        "    edge_list.append((b, a))\n",
        "\n",
        "# add product-social tag edges\n",
        "for p, s in ps_edges:\n",
        "    edge_list.append((p, P + s))\n",
        "    edge_list.append((P + s, p))\n",
        "\n",
        "# add product-social sim edges\n",
        "for p, s in ps_sim_edges:\n",
        "    edge_list.append((p, P + s))\n",
        "    edge_list.append((P + s, p))\n",
        "\n",
        "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
        "print('Total edges:', edge_index.size(1))\n",
        "\n",
        "# Node features: stack product_x and social_x\n",
        "# Ensure feature dims match by zero-padding the smaller tensor if needed\n",
        "print(f'product_x.shape = {product_x.shape}, social_x.shape = {social_x.shape}')\n",
        "if product_x.size(1) != social_x.size(1):\n",
        "    max_dim = max(product_x.size(1), social_x.size(1))\n",
        "    def pad_features(tensor, target_dim):\n",
        "        pad_size = target_dim - tensor.size(1)\n",
        "        if pad_size > 0:\n",
        "            padding = torch.zeros((tensor.size(0), pad_size), dtype=tensor.dtype)\n",
        "            return torch.cat([tensor, padding], dim=1)\n",
        "        return tensor\n",
        "\n",
        "    product_x = pad_features(product_x, max_dim)\n",
        "    social_x  = pad_features(social_x, max_dim)\n",
        "    print(f'Padded to match dims -> product_x.shape = {product_x.shape}, social_x.shape = {social_x.shape}')\n",
        "\n",
        "# Now safe to combine\n",
        "x = torch.cat([product_x, social_x], dim=0)\n",
        "print(f'Merged node feature shape: {x.shape}')\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Create PyG Data and train/test split for link prediction\n",
        "# ---------------------------\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "# train_test_split_edges expects 'data' to be undirected and will create data.train_pos_edge_index etc.\n",
        "data = train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1)\n",
        "\n",
        "# ---------------------------\n",
        "# 7) GraphSAGE encoder + Link Predictor (dot product)\n",
        "# ---------------------------\n",
        "class GraphSAGEEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, num_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        return x\n",
        "\n",
        "class LinkPredictor(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(emb_dim * 2, 1)\n",
        "\n",
        "    def forward(self, z, edge_index):\n",
        "        # edge_index: [2, E]\n",
        "        src = z[edge_index[0]]\n",
        "        dst = z[edge_index[1]]\n",
        "        out = self.lin(torch.cat([src, dst], dim=1))\n",
        "        return torch.sigmoid(out).squeeze(-1)\n",
        "\n",
        "# ---------------------------\n",
        "# 8) Training loop for link prediction\n",
        "# ---------------------------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "in_dim = data.num_features\n",
        "emb_dim = 128\n",
        "encoder = GraphSAGEEncoder(in_dim, emb_dim, num_layers=2, dropout=0.2).to(device)\n",
        "predictor = LinkPredictor(emb_dim).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(predictor.parameters()), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "def get_link_labels(pos_edge_index, neg_edge_index):\n",
        "    E_pos = pos_edge_index.size(1)\n",
        "    E_neg = neg_edge_index.size(1)\n",
        "    labels = torch.cat([torch.ones(E_pos), torch.zeros(E_neg)], dim=0).to(device)\n",
        "    return labels\n",
        "\n",
        "x = data.x.to(device)\n",
        "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
        "\n",
        "# We'll sample negative edges each epoch using negative_sampling\n",
        "epochs = 80\n",
        "for epoch in range(1, epochs + 1):\n",
        "    encoder.train()\n",
        "    predictor.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    z = encoder(x, data.train_pos_edge_index.to(device))\n",
        "\n",
        "    # positive edges\n",
        "    pos_edge = data.train_pos_edge_index.to(device)\n",
        "    # negative edges\n",
        "    neg_edge = negative_sampling(\n",
        "        edge_index=data.train_pos_edge_index.to(device), num_nodes=data.num_nodes,\n",
        "        num_neg_samples=pos_edge.size(1)\n",
        "    ).to(device)\n",
        "\n",
        "    # prepare edge_index for predictor (concatenate)\n",
        "    edge_idx = torch.cat([pos_edge, neg_edge], dim=1)\n",
        "    preds = predictor(z, edge_idx)\n",
        "    labels = get_link_labels(pos_edge, neg_edge)\n",
        "\n",
        "    loss = F.binary_cross_entropy(preds, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == 1:\n",
        "        # evaluate on val\n",
        "        encoder.eval()\n",
        "        predictor.eval()\n",
        "        with torch.no_grad():\n",
        "            z = encoder(x, data.train_pos_edge_index.to(device))\n",
        "            # val pos/neg\n",
        "            val_pos = data.val_pos_edge_index.to(device)\n",
        "            val_neg = data.val_neg_edge_index.to(device)\n",
        "            val_edge = torch.cat([val_pos, val_neg], dim=1)\n",
        "            val_preds = predictor(z, val_edge).cpu()\n",
        "            val_labels = get_link_labels(val_pos, val_neg).cpu()\n",
        "            from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "            try:\n",
        "                auc = roc_auc_score(val_labels.numpy(), val_preds.numpy())\n",
        "                ap = average_precision_score(val_labels.numpy(), val_preds.numpy())\n",
        "            except Exception:\n",
        "                auc, ap = 0.0, 0.0\n",
        "        print(f'Epoch {epoch:03d} | Loss {loss.item():.4f} | Val AUC {auc:.4f} | Val AP {ap:.4f}')\n",
        "\n",
        "# ---------------------------\n",
        "# 9) Produce final embeddings & hybrid recommendations\n",
        "# ---------------------------\n",
        "encoder.eval()\n",
        "with torch.no_grad():\n",
        "    final_z = encoder(x.to(device), data.train_pos_edge_index.to(device))\n",
        "    final_z = final_z.cpu().numpy()\n",
        "\n",
        "# Split product and social embeddings\n",
        "prod_z = final_z[:P]\n",
        "soc_z = final_z[P:]\n",
        "\n",
        "# Hybrid recommendation for a product p0:\n",
        "#  - graph_sim: cosine similarity in GNN-embedding space between products\n",
        "#  - content_sim: cosine similarity in original content embedding space (product_emb)\n",
        "# final_score = alpha * graph_sim + (1-alpha) * content_sim\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "prod_graph_sim = cosine_similarity(prod_z)\n",
        "prod_content_sim = cosine_similarity(product_emb)\n",
        "\n",
        "alpha = 0.6  # weight for graph vs content\n",
        "hybrid_sim = alpha * prod_graph_sim + (1 - alpha) * prod_content_sim\n",
        "\n",
        "# Recommendation function\n",
        "import numpy as np\n",
        "\n",
        "def recommend_for_product(prod_idx, top_k=10):\n",
        "    sims = hybrid_sim[prod_idx]\n",
        "    sims[prod_idx] = -1  # ignore self\n",
        "    idxs = np.argsort(-sims)[:top_k]\n",
        "    return idxs, sims[idxs]\n",
        "\n",
        "# Example usage: recommend for product 0\n",
        "rec_idxs, rec_scores = recommend_for_product(0, top_k=10)\n",
        "print('Recommended product indices:', rec_idxs)\n",
        "print('Scores:', rec_scores)\n",
        "\n",
        "# Map indices back to product ids/names\n",
        "for i, sc in zip(rec_idxs, rec_scores):\n",
        "    print(f'Product: {product_df.iloc[i].product_id} | {product_df.iloc[i].product_name[:80]} | score {sc:.4f}')\n",
        "\n",
        "# ---------------------------\n",
        "# 10) Extra suggestions & improvements\n",
        "# ---------------------------\n",
        "# - For larger graphs: use torch_geometric.loader.NeighborSampler or ClusterData + ClusterLoader\n",
        "# - Consider heterogeneous GNNs (HeteroData) if you want type-specific convs for products vs social\n",
        "# - Try other objectives: (a) supervised ranking using known product co-purchases, (b) BPR loss\n",
        "# - Add features: platform_type encoding, time-decay weighting for social mentions\n",
        "# - Use faiss or Annoy for fast nearest neighbour search in production\n",
        "# - Persist embeddings: save npy or to vector DB for online retrieval\n",
        "\n",
        "# Save embeddings\n",
        "np.save('prod_embeddings.npy', prod_z)\n",
        "np.save('social_embeddings.npy', soc_z)\n",
        "print('Saved embeddings to disk.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ph8ptOdev3AZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDOdxQD/DYKuBke07GCxcr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06a8f6c6691443d8b585fc265fadb174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_987f825816cc4dc28938a4de49889a8c",
              "IPY_MODEL_aa523e74a2ee4fc189b7d0279b156dc2",
              "IPY_MODEL_23e2e81d8de6490ab6b71918d2a7c0d0"
            ],
            "layout": "IPY_MODEL_266c11a578c14dd388fd651b3a8e8138"
          }
        },
        "987f825816cc4dc28938a4de49889a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b197dd5456194748953319de2e1a6ab2",
            "placeholder": "​",
            "style": "IPY_MODEL_a4caa3e0cd3d497e90f5bb1882b00165",
            "value": "Batches: 100%"
          }
        },
        "aa523e74a2ee4fc189b7d0279b156dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd26d1d3d4443cb9e893052e10e5c1c",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d71b94e2e052414e8254435d0d0e8d9d",
            "value": 32
          }
        },
        "23e2e81d8de6490ab6b71918d2a7c0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fcf1a2ee47a4556b6645db4aed58ac7",
            "placeholder": "​",
            "style": "IPY_MODEL_284a912d7c8e435abba37b4bf8bd993e",
            "value": " 32/32 [00:25&lt;00:00,  2.62it/s]"
          }
        },
        "266c11a578c14dd388fd651b3a8e8138": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b197dd5456194748953319de2e1a6ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4caa3e0cd3d497e90f5bb1882b00165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffd26d1d3d4443cb9e893052e10e5c1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71b94e2e052414e8254435d0d0e8d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fcf1a2ee47a4556b6645db4aed58ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "284a912d7c8e435abba37b4bf8bd993e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac4701d881a2496ab6cf550b6f8fe411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68574b0dae7741ac889e0be40136171c",
              "IPY_MODEL_ab8e4c075bdd4f41ad6c9cb247647af5",
              "IPY_MODEL_9d8120369b3849c1ad6f3445ce88e35f"
            ],
            "layout": "IPY_MODEL_1cb0baaf14004ac3820c700d4e76cf0c"
          }
        },
        "68574b0dae7741ac889e0be40136171c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f518c73749f441a8a0c888da7c16b5ef",
            "placeholder": "​",
            "style": "IPY_MODEL_efb3a9f65ec74b2098913f5463663e15",
            "value": "Batches: 100%"
          }
        },
        "ab8e4c075bdd4f41ad6c9cb247647af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_366c8250dc8442d1a6a05552683f25f0",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0768d6a2d564f0eb804b4bcfd5bd2e9",
            "value": 32
          }
        },
        "9d8120369b3849c1ad6f3445ce88e35f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b43b0187755f41329194be72d2ed1914",
            "placeholder": "​",
            "style": "IPY_MODEL_053130f4bb70432781064ea3c2821f57",
            "value": " 32/32 [00:20&lt;00:00,  5.88it/s]"
          }
        },
        "1cb0baaf14004ac3820c700d4e76cf0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f518c73749f441a8a0c888da7c16b5ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb3a9f65ec74b2098913f5463663e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "366c8250dc8442d1a6a05552683f25f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0768d6a2d564f0eb804b4bcfd5bd2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b43b0187755f41329194be72d2ed1914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "053130f4bb70432781064ea3c2821f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}